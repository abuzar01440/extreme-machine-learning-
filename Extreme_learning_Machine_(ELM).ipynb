{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extreme learning Machine\n"
      ],
      "metadata": {
        "id": "6Ix7JKkIVfqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "X = np.array([\n",
        "    [0.85, 0.32, 0.68],  # Gabor feature 1, Gabor feature 2, Gabor feature 3 (Tumor)\n",
        "    [0.23, 0.234, 0.1]])\n",
        "y= np.array([10, 90])  # 1 for Tumor, 0 for Healthy\n",
        "\n",
        "\n",
        "class ELM:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Randomly initialize input weights and biases (key ELM aspect)\n",
        "        self.input_weights = tf.Variable(tf.random.normal([input_size, hidden_size]))\n",
        "        self.biases = tf.Variable(tf.random.normal([hidden_size]))\n",
        "\n",
        "        # Output weights will be learned\n",
        "        self.output_weights = tf.Variable(tf.zeros([hidden_size, output_size]))\n",
        "\n",
        "    def hidden_layer(self, X):\n",
        "        X = tf.cast(X, tf.float32)  # Cast X to float32\n",
        "        H = tf.nn.sigmoid(tf.matmul(X, self.input_weights) + self.biases)  # Activation function\n",
        "        return H\n",
        "\n",
        "    def train(self, X, y):\n",
        "        H = self.hidden_layer(X)\n",
        "        # Solve for output weights using pseudo-inverse (or regularized methods)\n",
        "        y = tf.cast(y, tf.float32) # Cast y to float32\n",
        "        self.output_weights.assign(tf.linalg.pinv(H) @ tf.reshape(y, [-1, 1])) # Reshape y to a column vector\n",
        "\n",
        "    def predict(self, X):\n",
        "        H = self.hidden_layer(X)\n",
        "        y_pred = tf.matmul(H, self.output_weights)\n",
        "        return y_pred\n",
        "\n",
        "# Example Usage\n",
        "model = ELM(input_size=X.shape[1], hidden_size=6, output_size=1)  # 24 hidden nodes\n",
        "model.train(X, y)\n",
        "predictions = model.predict(X)\n",
        "print(\"--\"*26)\n",
        "print(predictions)\n",
        "print(\"--\"*26)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7BEjHgqcmSb",
        "outputId": "c0c3572a-f874-49f4-ddcb-1987668eef6f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------\n",
            "tf.Tensor(\n",
            "[[10.000015]\n",
            " [90.00001 ]], shape=(2, 1), dtype=float32)\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Initialization: The input_weights and biases are randomly initialized and not updated during training. This is a fundamental characteristic of ELMs that contributes to their speed.\n",
        "\n",
        "Activation Function: The code uses the sigmoid activation function (tf.nn.sigmoid), but you can experiment with other functions like ReLU, tanh, etc.\n",
        "\n",
        "Output Weight Calculation: The output weights are calculated using the pseudo-inverse (tf.linalg.pinv).\n",
        "\n",
        "Hidden Layer Size: The paper uses 24 hidden nodes (hidden_size=24). You might need to tune this hyperparameter\n",
        "based on your dataset and problem complexity.\n",
        "TensorFlow Integration: This implementation leverages TensorFlow for efficient matrix operations and potential GPU acceleration."
      ],
      "metadata": {
        "id": "ZpnLca3RWTsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ELMRegressor_TensorFlow"
      ],
      "metadata": {
        "id": "-jVbfRl7On5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ELMRegressor_TF:\n",
        "    def __init__(self, n_hidden_units):\n",
        "        self.n_hidden_units = n_hidden_units\n",
        "\n",
        "    def fit(self, X, labels):\n",
        "        # Convert inputs to tensors\n",
        "        X = tf.constant(X, dtype=tf.float32)\n",
        "        labels = tf.constant(labels, dtype=tf.float32)\n",
        "\n",
        "        # Add bias column (ones)\n",
        "        X = tf.concat([X, tf.ones([tf.shape(X)[0], 1], dtype=tf.float32)], axis=1)\n",
        "\n",
        "        # Initialize random weights and calculate G (hidden layer output)\n",
        "        self.random_weights = tf.Variable(\n",
        "            tf.random.normal([tf.shape(X)[1], self.n_hidden_units], dtype=tf.float32)\n",
        "        )\n",
        "        G = tf.nn.tanh(tf.matmul(X, self.random_weights))\n",
        "\n",
        "        # Compute output weights (w_elm) using pseudo-inverse\n",
        "        self.w_elm = tf.matmul(tf.linalg.pinv(G), labels)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Convert input and add bias\n",
        "        X = tf.constant(X, dtype=tf.float32)\n",
        "        X = tf.concat([X, tf.ones([tf.shape(X)[0], 1], dtype=tf.float32)], axis=1)\n",
        "\n",
        "        # Calculate hidden layer output and predictions--> REGRESSOR\n",
        "        G = tf.nn.tanh(tf.matmul(X, self.random_weights))\n",
        "        return tf.matmul(G, self.w_elm)\n",
        "\n",
        "\n",
        "# difference b/w both ELM model first and 2nd implementation?\n",
        "\n",
        "# For most regression tasks, ELMRegressor_TF (using tanh activation and implicit bias handling)\n",
        "#is generally preferred or considered a more robust choice for the hidden layer activation function."
      ],
      "metadata": {
        "id": "8uNdOyoGOCjh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "X = tf.constant([[1, 2], [3, 4], [5, 6]], dtype=tf.float32)\n",
        "labels = tf.constant([[10], [20], [30]], dtype=tf.float32)\n",
        "\n",
        "# Create and train the model\n",
        "elm_regressor = ELMRegressor_TF(n_hidden_units=10)\n",
        "elm_regressor.fit(X, labels)\n",
        "\n",
        "# Make predictions\n",
        "new_X = tf.constant([[7, 8], [9, 10]], dtype=tf.float32)\n",
        "predictions = elm_regressor.predict(new_X)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVB7kOyzWWPc",
        "outputId": "f532def2-a744-4d0c-ed3d-7d25c4c9e9d5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[39.679764]\n",
            " [49.39465 ]], shape=(2, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# eXTREME Machine Learning (ELM) Regressor"
      ],
      "metadata": {
        "id": "tZjp-MBpZMGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "perform better than normal"
      ],
      "metadata": {
        "id": "gXWEEx5pQwGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now normal\n",
        "\n",
        "class ELM_TF:\n",
        "    def __init__(self, input_size, output_size, hidden_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # TensorFlow Variable initialization for weights and bias\n",
        "        self.weight = tf.Variable(\n",
        "            tf.random.normal([self.hidden_size, self.input_size], -0.5, 0.5, dtype=tf.float32)\n",
        "        )\n",
        "        self.bias = tf.Variable(\n",
        "            tf.random.normal([1, self.hidden_size], 0, 1, dtype=tf.float32)\n",
        "        )\n",
        "        self.beta = None  # Will be initialized during training\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return tf.math.sigmoid(x)  # TensorFlow's sigmoid activation\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = tf.cast(X, tf.float32)\n",
        "        H = self.sigmoid(tf.matmul(X, tf.transpose(self.weight)) + self.bias)\n",
        "        return tf.matmul(H, self.beta)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X = tf.cast(X, tf.float32)\n",
        "        y = tf.cast(y, tf.float32)\n",
        "\n",
        "        # Calculate hidden layer output\n",
        "        H = self.sigmoid(tf.matmul(X, tf.transpose(self.weight)) + self.bias)\n",
        "\n",
        "        # Compute beta (output weights) using TensorFlow's pseudo-inverse\n",
        "        H_pinv = tf.linalg.pinv(tf.matmul(tf.transpose(H), H))\n",
        "        self.beta = tf.matmul(tf.matmul(H_pinv, tf.transpose(H)), y)\n",
        "\n",
        "        # Return training predictions (optional, for evaluation)\n",
        "        return tf.matmul(H, self.beta)\n"
      ],
      "metadata": {
        "id": "jj8uWi3IPjGI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample training data\n",
        "X_train = tf.constant([[1, 2], [3, 4], [5, 6], [7,8]], dtype=tf.float32)\n",
        "y_train = tf.constant([[10], [20], [30], [40]], dtype=tf.float32)\n",
        "\n",
        "# Create and train the model\n",
        "elm_tf = ELM_TF(input_size=2, output_size=1, hidden_size=10)\n",
        "elm_tf.train(X_train, y_train)\n",
        "\n",
        "# Make predictions on new data\n",
        "X_test = tf.constant([[7, 8], [9, 10]], dtype=tf.float32)\n",
        "predictions = elm_tf.predict(X_test)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjt62s37P-FW",
        "outputId": "4ac15505-ca68-406f-c0ad-4d50538dd3ed"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[40.      ]\n",
            " [48.164974]], shape=(2, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RESULTS ARE little bit AWESOME BUT VERY CLOSE, BECZ THE TRAINING DATASET IN VERY SMALL"
      ],
      "metadata": {
        "id": "KcspX-QhdVN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "-gNFd9FufWCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ELM_classifier:\n",
        "    def __init__(self, input_size, output_size, hidden_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # TensorFlow Variable initialization for weights and bias\n",
        "        self.weight = tf.Variable(\n",
        "            tf.random.uniform([self.hidden_size, self.input_size], -1, 1, dtype=tf.float32)\n",
        "        )\n",
        "        self.bias = tf.Variable(\n",
        "            tf.random.uniform([self.hidden_size], -1, 1, dtype=tf.float32)\n",
        "        )\n",
        "        self.beta = None  # Will be initialized during training\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return tf.math.sigmoid(x)  # TensorFlow's sigmoid activation\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = tf.cast(X, tf.float32)\n",
        "        H = self.sigmoid(tf.matmul(X, tf.transpose(self.weight)) + self.bias)\n",
        "        return tf.matmul(H, self.beta)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X = tf.cast(X, tf.float32)\n",
        "        y = tf.cast(y, tf.float32)\n",
        "        y = tf.reshape(y, [-1, 1])  # Ensure y is a column vector\n",
        "\n",
        "        # Calculate hidden layer output\n",
        "        H = self.sigmoid(tf.matmul(X, tf.transpose(self.weight)) + self.bias)\n",
        "\n",
        "        # Compute beta (output weights) using TensorFlow's pseudo-inverse or other methods\n",
        "        # Here's the pseudo-inverse approach:\n",
        "        H_pinv = tf.linalg.pinv(H)\n",
        "        self.beta = tf.matmul(H_pinv, y)\n",
        "\n",
        "        # Return training predictions (optional, for evaluation)\n",
        "        return tf.matmul(H, self.beta)\n",
        "\n",
        "# Example usage (same as before)\n",
        "X_train = np.array([\n",
        "    [0.85, 0.32, 0.68],\n",
        "    [0.12, 0.91, 0.25],\n",
        "    [0.79, 0.45, 0.55],\n",
        "    [0.21, 0.88, 0.33],\n",
        "    [0.92, 0.28, 0.71]\n",
        "])\n",
        "\n",
        "y_train = np.array([1, 0, 1, 0, 1])\n",
        "\n",
        "X_train = tf.constant(X_train, dtype=tf.float32)\n",
        "y_train = tf.constant(y_train, dtype=tf.float32)\n",
        "\n",
        "# Create and train the model\n",
        "elm_tf_classifier = ELM_classifier(input_size=3, output_size=1, hidden_size=10) # we have three columns so input size =3\n",
        "elm_tf_classifier.train(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "LGrguZLfQCEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23459dd5-2cd5-414f-9d28-a08ffb5223d2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
              "array([[ 1.0000005e+00],\n",
              "       [-2.8610229e-06],\n",
              "       [ 9.9999285e-01],\n",
              "       [ 0.0000000e+00],\n",
              "       [ 1.0000014e+00]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train data"
      ],
      "metadata": {
        "id": "sWpmNxcoUkQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "guess = elm_tf_classifier.predict(X_train)\n",
        "predictions = guess.numpy()  # Convert tensor to NumPy array\n",
        "print(predictions)\n",
        "for i, prediction in enumerate(predictions):\n",
        "    if prediction > 0.5:\n",
        "        print(f\"Sample {i+1}: Tumor (Probability: {prediction[0]:.2f})\")\n",
        "    else:\n",
        "        print(f\"Sample {i+1}: Healthy (Probability: {1 - prediction[0]:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs5uFRUNSsUa",
        "outputId": "c87140ac-e0af-469f-982f-969bd1ea6616"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.0000005e+00]\n",
            " [-2.8610229e-06]\n",
            " [ 9.9999285e-01]\n",
            " [ 0.0000000e+00]\n",
            " [ 1.0000014e+00]]\n",
            "Sample 1: Tumor (Probability: 1.00)\n",
            "Sample 2: Healthy (Probability: 1.00)\n",
            "Sample 3: Tumor (Probability: 1.00)\n",
            "Sample 4: Healthy (Probability: 1.00)\n",
            "Sample 5: Tumor (Probability: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test data"
      ],
      "metadata": {
        "id": "rcdcmU4HUpNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([\n",
        "    [0.81, 0.38, 0.62],  # Gabor feature 1, Gabor feature 2, Gabor feature 3 (Tumor)\n",
        "    [0.18, 0.85, 0.30]   # ... (Healthy)\n",
        "])\n",
        "\n",
        "y_test = np.array([1, 0])  # 1 for Tumor, 0 for Healthy\n",
        "\n",
        "\n",
        "X_test = tf.constant(X_test, dtype=tf.float32)\n",
        "y_test = tf.constant(y_test, dtype=tf.float32)\n",
        "\n",
        "guess_test = elm_tf_classifier.predict(X_test)\n",
        "guess_test = guess_test.numpy()  # Convert tensor to NumPy array\n",
        "print(guess_test)\n",
        "\n",
        "for i, prediction_1 in enumerate(guess_test):\n",
        "    if prediction_1 > 0.5:\n",
        "        print(f\"Sample {i+1}: Tumor (Probability: {prediction[0]:.2f})\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Sample {i+1}: Healthy (Probability: {1 - prediction[0]:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81npX2AvS4D6",
        "outputId": "c748f23d-4892-45e4-dd30-692173ee9ed5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0056949 ]\n",
            " [0.14818382]]\n",
            "Sample 1: Tumor (Probability: 1.00)\n",
            "Sample 2: Healthy (Probability: -0.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nHpG-RI1U2mz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}